{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b1992c1-8d83-4acd-ba0f-c71ddcc7f031",
   "metadata": {},
   "source": [
    "## $\\alpha$ = v, $\\ell_0$ = v, beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dd20a9c-2948-4206-a7e5-e8f241d7cbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import healpy as hp\n",
    "import matplotlib.pyplot as plt\n",
    "import fgbuster\n",
    "import pysm3\n",
    "import pysm3.units as u\n",
    "import pandas as pd\n",
    "import emcee\n",
    "import camb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "\n",
    "from fgbuster import CMB, Dust, Synchrotron, get_instrument, MixingMatrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ad05b5-741f-4a89-8800-6e4c94cbde20",
   "metadata": {},
   "outputs": [],
   "source": [
    "specifications = {\n",
    "    28: (39.9, 16.5),\n",
    "    35: (31.9, 13.3),\n",
    "    45: (24.8, 11.9),\n",
    "    65: (17.1, 8.9),\n",
    "    75: (14.91, 5.1),\n",
    "    95: (11.7, 4.6),\n",
    "    115: (9.72, 3.1),\n",
    "    130: (8.59, 3.1),\n",
    "    145: (7.70, 2.4),\n",
    "    165: (6.77, 2.5),\n",
    "    190: (5.88, 2.8),\n",
    "    220: (5.08, 3.3),\n",
    "    275: (4.06, 6.3),\n",
    "    340: (3.28, 11.4),\n",
    "    390: (2.86, 21.9),\n",
    "    450: (2.48, 43.4),\n",
    "    520: (2.14, 102.0),\n",
    "    600: (1.86, 288.0),\n",
    "    700: (1.59, 1122.0),\n",
    "    850: (1.31, 9550.0),\n",
    "}\n",
    "\n",
    "# frequency_channels = np.array([28, 65, 115, 165, 275, 450, 700])\n",
    "frequency_channels = np.array([28, 35, 45, 65, 75, 95, 115, 130, 145, 165, 190, 220, 275, 340, 390, 450, 520, 600, 700, 850])[:]\n",
    "nfreqs = len(frequency_channels)\n",
    "\n",
    "noise_rms_pol = np.array([specifications[int(frequency)][1] for frequency in frequency_channels])\n",
    "noise_rms_temp = noise_rms_pol / np.sqrt(2)\n",
    "beams = np.array([specifications[int(frequency)][0] for frequency in frequency_channels])\n",
    "\n",
    "conv_factor = (np.pi/(180 * 60))\n",
    "\n",
    "noise_rms_pol = noise_rms_pol * conv_factor\n",
    "noise_rms_temp = noise_rms_temp * conv_factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d8efd5-b086-43df-b393-757d2417ba86",
   "metadata": {},
   "source": [
    "## 1. Simulations and Power Spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63ec90fc-922d-421d-9447-3f8444918ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the theoretical power spectrum file.\n",
    "thdl_file_path = 'cmb_new_ps_l.txt'\n",
    "\n",
    "# Read the theoretical Dl power spectra.\n",
    "# The file is assumed to have no header, with the first column as ℓ values (set as index)\n",
    "# and columns 1, 2, 3, 4 corresponding to Dl for TT, EE, BB, and TE respectively.\n",
    "thdl = pd.read_csv(thdl_file_path, sep='\\t', header=None, index_col=0)\n",
    "\n",
    "# Extract the ell values from the DataFrame index.\n",
    "thdl_l = thdl.index.values\n",
    "\n",
    "# Determine the maximum multipole from the input file.\n",
    "lmax = int(np.max(thdl_l))\n",
    "\n",
    "# Extract the theoretical Dl power spectra for TT, EE, BB, and TE.\n",
    "thdl_tt = thdl[1].values\n",
    "thdl_ee = thdl[2].values\n",
    "thdl_bb = thdl[3].values\n",
    "thdl_te = thdl[4].values\n",
    "\n",
    "# Compute the normalization factor f(ℓ) = ℓ(ℓ+1)/(2π)\n",
    "fl = (thdl_l * (thdl_l + 1)) / (2 * np.pi)\n",
    "\n",
    "# Normalize the spectra (convert Dl to Cl) for ℓ >= 2.\n",
    "thcl_tt = thdl_tt / fl\n",
    "thcl_ee = thdl_ee / fl\n",
    "thcl_bb = thdl_bb / fl\n",
    "thcl_te = thdl_te / fl\n",
    "\n",
    "# Create an array for Cl with shape (4, lmax+1), initializing all values to zero.\n",
    "# The four rows correspond to TT, EE, BB, and TE respectively.\n",
    "cmb_theory_cl = np.zeros((4, lmax+1), dtype=np.float64)\n",
    "cmb_theory_cl[0, 2:] = thcl_tt\n",
    "cmb_theory_cl[1, 2:] = thcl_ee\n",
    "cmb_theory_cl[2, 2:] = thcl_bb\n",
    "cmb_theory_cl[3, 2:] = thcl_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d1d530-4ed4-4db1-9a8f-5e91e8c77909",
   "metadata": {},
   "outputs": [],
   "source": [
    "nside = 128\n",
    "nlmax = 2 * nside\n",
    "alpha = -np.arange(10, 50, 2)/10\n",
    "ell0 = np.round(np.linspace(2, nlmax, nfreqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c266c02-46a3-40bc-bfcf-95b4bd3318c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_resol = 39.9*u.arcmin\n",
    "target_beam = hp.gauss_beam(np.radians(target_resol.value/60), lmax= 3*nside - 1, pol=True)\n",
    "target_beam_T = target_beam[:,0]\n",
    "target_beam_p = target_beam[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cc496d7-864d-4686-a073-7bbc80a0daf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_f = np.array([hp.gauss_beam(np.radians(theta/60.0), lmax= 3*nside - 1, pol=True).T for theta in beams])\n",
    "beam_T = b_f[:,0]\n",
    "beam_pol = b_f[:,1]\n",
    "ratio_T = np.array(target_beam_T/beam_T)[:,:nlmax+1]\n",
    "ratio_P = (target_beam_p/beam_pol)[:,:nlmax+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc484302-665c-4f44-99dc-f8b4c6f08707",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_config = pysm3.Sky(nside=nside, \n",
    "                    preset_strings=[\"d0\", \"s0\"],  # Synchrotron ('s0') and Thermal Dust ('d0') models\n",
    "                    output_unit=\"uK_CMB\")  # Output units in microKelvin (CMB temperature units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a745d30-c581-4c39-b3d0-293434c3d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "foreground_balms = np.zeros((nfreqs, hp.Alm.getsize(nlmax)), dtype = np.complex128)\n",
    "for j, frequency in enumerate(frequency_channels):\n",
    "    foreground_input_map = foreground_config.get_emission(frequency * u.GHz)\n",
    "    foreground_balms[j] = hp.almxfl(hp.map2alm(foreground_input_map, lmax = nlmax)[2], target_beam_p)  #only [2] which is B-mode is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6a1312-519a-4f90-beff-a736a077c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise spectra function using a depth array (sigma_rms of size Nf)\n",
    "def Noise_Spectra(noise_rms, alpha_knee, l_knee, nlmax):\n",
    "    Nf_local = len(noise_rms)\n",
    "    N = np.zeros((nlmax+1, Nf_local, Nf_local))\n",
    "    noise_white = noise_rms**2 #np.power(noise_rms, 2.0)\n",
    "\n",
    "    ratio_matrix = np.array([np.diag(row) for row in ratio_P.T])\n",
    "    \n",
    "    for l in range(2, nlmax+1):\n",
    "        noise_sp = noise_white * (1 + (l / l_knee)**alpha_knee)\n",
    "        N[l] = ratio_matrix[l].T @ np.diag(noise_sp) @ ratio_matrix[l]\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66908572-c5df-407d-96ac-f35c41a786d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Noise_White(noise_rms, nlmax):\n",
    "    Nf_local = len(noise_rms)\n",
    "    N = np.zeros((nlmax+1, Nf_local, Nf_local))\n",
    "    noise_white = noise_rms**2 #np.power(noise_rms, 2.0)\n",
    "    for l in range(2, nlmax+1):\n",
    "        noise_sp = noise_white #* (1 + (l / l_knee)**alpha_knee)\n",
    "        N[l] = np.diag(noise_sp)\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "265d04a4-ec03-46fd-bc9e-b88c7d71aa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMB_Spectra(cmb_spec, nlmax):\n",
    "    Nf_local = len(frequency_channels)\n",
    "    CMB_sp = np.zeros((nlmax+1, Nf_local, Nf_local))\n",
    "    for l in range(2, nlmax+1):\n",
    "        CMB_sp[l] += cmb_spec[l] * target_beam_p[l]**2\n",
    "    return CMB_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "337a6fba-3f26-46df-86ad-73f99777accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Observation_Spectra(alms):\n",
    "    Nf_local = alms.shape[0]\n",
    "    alm_size = alms.shape[-1]\n",
    "    nlmax = hp.Alm.getlmax(alm_size)\n",
    "    \n",
    "    # Allocate array for Cl; for each l, we have an n_channels x n_channels matrix.\n",
    "    C = np.zeros((nlmax+1, Nf_local, Nf_local))\n",
    "    \n",
    "    # Loop over channel pairs.\n",
    "    for f in range(Nf_local):\n",
    "        for g in range(f, Nf_local):\n",
    "            # Compute the cross-power spectrum between channel f and g.\n",
    "            C_fg = hp.alm2cl(alms[f], alms[g], lmax = nlmax)\n",
    "            C[:, f, g] = C_fg\n",
    "            C[:, g, f] = C_fg  # symmetry: C_ij = C_ji.\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65f31ea3-3e71-43ed-a875-89ae0593dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a combined observation power spectrum of cmb, foreground and noise of shape (nlmax+1, nfreqs, nfreqs) for only B-modes\n",
    "\n",
    "#cmb\n",
    "cmb_sp = CMB_Spectra(cmb_theory_cl[2], nlmax)\n",
    "\n",
    "#foregrounds\n",
    "foreground_sp = Observation_Spectra(foreground_balms)\n",
    "# foreground_sp = Observation_Spectra(foreground_input_maps)\n",
    "\n",
    "#noise\n",
    "noise_sp = Noise_Spectra(noise_rms_pol, alpha_knee = alpha, l_knee = ell0, nlmax = nlmax)\n",
    "\n",
    "combined_obs_sp = cmb_sp + foreground_sp + noise_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f1affea-c125-4f78-9db0-d0ca74f26a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_params(true_params, pct=0.1):\n",
    "    lb = true_params - pct * np.abs(true_params)\n",
    "    ub = true_params + pct * np.abs(true_params)\n",
    "    return np.random.uniform(lb, ub)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce83668-4e3f-430c-9991-aa46ed087e7c",
   "metadata": {},
   "source": [
    "## 2. Ensemble Averaged Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c8fab68-cc3a-40f5-9235-cb1839068b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmb = CMB()\n",
    "dust = Dust(353)\n",
    "synch = Synchrotron(20)\n",
    "sky_components = [cmb, dust, synch]\n",
    "ncomps = len(sky_components)\n",
    "\n",
    "MM = MixingMatrix(*sky_components)\n",
    "A_evaluator = MM.evaluator(frequency_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd663efe-efa2-41fb-a611-7b85e5fdfde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EnsembleAverageNegative2LogLikelihood(params, noise_rms, obs_sp, noise_sp):\n",
    "\n",
    "    # Determine maximum multipole from Cl_d.\n",
    "    nlmax_local = obs_sp.shape[0] - 1\n",
    "    Nf_local = obs_sp.shape[1]\n",
    "    \n",
    "    # Unpack parameters.\n",
    "    alpha_knee = params[:nfreqs]\n",
    "    l_knee = params[nfreqs:2*nfreqs]\n",
    "    spectral_params = params[-3:]\n",
    "    \n",
    "    # Evaluate the mixing matrix A (assumed to be computed from spectral_params).\n",
    "    A = A_evaluator(spectral_params)  # Expected shape: (n_freq, n_components)\n",
    "\n",
    "    # Compute noise spectra N for each multipole.\n",
    "    # Noise_Spectra returns an array of shape (lmax_local+1, n_freq, n_freq).\n",
    "    N = Noise_Spectra(noise_rms, alpha_knee, l_knee, nlmax_local)\n",
    "    \n",
    "    total = 0.0\n",
    "    for l in range(2, nlmax_local + 1):\n",
    "        # Get noise covariance for multipole l.\n",
    "        N_l = N[l]  # shape: (n_freq, n_freq)\n",
    "        N_inv_l = np.linalg.inv(N_l)\n",
    "        \n",
    "        C_l = obs_sp[l]\n",
    "        # N_l_th = noise_sp[l]\n",
    "        \n",
    "        # First term: (2l+1)*Tr[N_l^{-1} C^d_l]\n",
    "        D_term = np.trace(np.dot(N_inv_l, C_l))\n",
    "        \n",
    "        # Compute P_l = A^T N_l^{-1} A, then its inverse.\n",
    "        P_l = np.dot(np.dot(A.T, N_inv_l), A)\n",
    "        P_inv_l = np.linalg.inv(P_l)\n",
    "        \n",
    "        # Second term: (2l+1)*Tr[P_l^{-1} A^T N_l^{-1} C^d_l N_l^{-1} A]\n",
    "        X_term = np.trace(np.dot(P_inv_l, np.dot(np.dot(A.T, N_inv_l), np.dot(C_l, np.dot(N_inv_l, A)))))\n",
    "        \n",
    "        # Third term: (2l+1)[ln(2π) + ln(det(N_l))]\n",
    "        M_term = Nf_local * np.log(2*np.pi) + np.log(np.linalg.det(N_l))\n",
    "        \n",
    "        total += (2*l + 1) * (D_term - X_term + M_term)\n",
    "\n",
    "        #bias corrections\n",
    "        ANA = P_l\n",
    "        W = P_inv_l @ A.T @ N_inv_l\n",
    "\n",
    "        N_l_th = Noise_White(noise_rms, nlmax_local)[l]\n",
    "\n",
    "        #bias term 1: (2l+1)*Tr[W^T A^T N_l^{-1} N_l_th]\n",
    "        b1 = np.trace(W.T @ A.T @ N_inv_l @ N_l_th)\n",
    "\n",
    "        #bias term 2: (2l+1)*Tr[N_l_th N_l^{-1} A W]\n",
    "        b2 = np.trace(N_l_th @ N_inv_l @ A @ W)\n",
    "\n",
    "        #bias term 3: (2l+1)*Tr[W^T A^T N_l^{-1} A W N_l_th]\n",
    "        b3 = np.trace(W.T @ A.T @ N_inv_l @ A @ W @ N_l_th)\n",
    "\n",
    "        total+= (2*l + 1) * (b1 + b2 - b3)\n",
    "        \n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39151460-7dfc-4040-a966-636c73ead91d",
   "metadata": {},
   "source": [
    "## 3. Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6baf86d5-a63a-4b3b-b546-24e1e6637dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.  ,  -1.2 ,  -1.4 ,  -1.6 ,  -1.8 ,  -2.  ,  -2.2 ,  -2.4 ,\n",
       "        -2.6 ,  -2.8 ,  -3.  ,  -3.2 ,  -3.4 ,  -3.6 ,  -3.8 ,  -4.  ,\n",
       "        -4.2 ,  -4.4 ,  -4.6 ,  -4.8 ,   2.  ,  15.  ,  29.  ,  42.  ,\n",
       "        55.  ,  69.  ,  82.  ,  96.  , 109.  , 122.  , 136.  , 149.  ,\n",
       "       162.  , 176.  , 189.  , 203.  , 216.  , 229.  , 243.  , 256.  ,\n",
       "         1.54,  20.  ,  -3.  ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec_params = [1.54, 20, -3]\n",
    "\n",
    "true_params = np.concatenate([alpha, ell0, spec_params])\n",
    "true_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08f4237b-f3f2-426a-9ed2-08159706249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_params = generate_initial_params(true_params, pct=0.1)\n",
    "# print(\"\\n All initial parameters:\")\n",
    "# print(initial_params)\n",
    "\n",
    "# # Minimize the ensemble average negative 2 log-likelihood using Nelder-Mead.\n",
    "# result = minimize(\n",
    "# EnsembleAverageNegative2LogLikelihood,\n",
    "# initial_params,\n",
    "# args=(noise_rms_pol, combined_obs_sp, noise_sp),\n",
    "# method='Nelder-Mead',\n",
    "# options={'fatol': 1e-4, 'xatol': 1e-4, 'maxfev': 20000, 'disp': False, 'adaptive': True}\n",
    "# )\n",
    "\n",
    "# all_estimated_params = result.x\n",
    "# print(\"\\nAll estimated spectral parameters:\")\n",
    "# print(all_estimated_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fc4ce9-5e8d-4cba-859f-067e08786e0d",
   "metadata": {},
   "source": [
    "## 4. Minimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e18fd08-fa83-4087-bafe-fe4b81776876",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Positive2LogLikelihood(params, noise_rms, obs_sp, noise_sp):\n",
    "    return -1 * EnsembleAverageNegative2LogLikelihood(params, noise_rms, obs_sp, noise_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ada91a4-a6d9-450c-a328-0daf460d9940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_prior(params):\n",
    "    alpha = params[:nfreqs]\n",
    "    ell0 = params[nfreqs:2*nfreqs]\n",
    "    beta_d, T_d, beta_s  = params[-3:]\n",
    "    if (\n",
    "        np.all((alpha > -6) & (alpha < 0)) and\n",
    "        np.all((ell0 > 0) & (ell0 < nlmax+50)) and\n",
    "        1 < beta_d < 2 and\n",
    "        10 < T_d < 25 and\n",
    "        -5 < beta_s < -1\n",
    "    ):\n",
    "        return 0.0\n",
    "    return -np.inf\n",
    "\n",
    "\n",
    "def log_posterior(params, noise_rms, obs_sp, noise_sp):\n",
    "    lp = log_prior(params)\n",
    "    if not np.isfinite(lp):\n",
    "        # print(\"Prior is -inf for params:\", params)\n",
    "        return -np.inf\n",
    "    ll = EnsembleAverageNegative2LogLikelihood(params, noise_rms, obs_sp, noise_sp)\n",
    "    if not np.isfinite(ll):\n",
    "        # print(\"Likelihood is -inf for params:\", params)\n",
    "        return -np.inf\n",
    "    return -(lp + ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af857aa-f4d8-4a4f-bd6d-8f0e2fe54341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import emcee\n",
    "def get_samples(data, init, noise_sp):\n",
    "    ndim = len(init)\n",
    "    nwalkers = 3 * ndim  \n",
    "    nsteps = 25000\n",
    "    pos = init + 1e-1 * np.random.rand(nwalkers, ndim)\n",
    "    \n",
    "    sampler = emcee.EnsembleSampler(\n",
    "        nwalkers, ndim, log_posterior, args=(noise_rms_pol, data, noise_sp),\n",
    "    )\n",
    "    \n",
    "    state = sampler.run_mcmc(pos, nsteps//5, progress=True)\n",
    "    sampler.reset()\n",
    "\n",
    "    sampler.run_mcmc(state, nsteps, progress=True)\n",
    "    samples = sampler.get_chain(flat=True)\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1bcf4b04-ed28-4eed-9c50-697ee6382e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5000/5000 [26:43:53<00:00, 19.25s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 25000/25000 [125:49:31<00:00, 18.12s/it]\n"
     ]
    }
   ],
   "source": [
    "initial_params = true_params\n",
    "samples_fm = get_samples(combined_obs_sp, initial_params, noise_sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9547523c-f4c3-4f8c-9840-a8cc6b15ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.95900728e+00, -2.44409133e-01, -9.04650530e-01, -1.38935928e+00,\n",
       "       -1.39553975e+00, -1.72507052e+00, -1.70507309e+00, -2.02175661e+00,\n",
       "       -2.06858370e+00, -2.38551274e+00, -2.71242932e+00, -2.99088823e+00,\n",
       "       -3.27664444e+00, -3.42296847e+00, -3.65403232e+00, -3.84632091e+00,\n",
       "       -4.05787485e+00, -4.28553837e+00, -4.53879060e+00, -4.81045186e+00,\n",
       "        5.99701482e+00,  9.28467047e-01,  2.66319617e+01,  4.33071800e+01,\n",
       "        5.71223362e+01,  7.27704148e+01,  9.00504380e+01,  1.05330795e+02,\n",
       "        1.22801404e+02,  1.34162956e+02,  1.43994271e+02,  1.53998717e+02,\n",
       "        1.64358999e+02,  1.79214190e+02,  1.92128366e+02,  2.06431069e+02,\n",
       "        2.18432343e+02,  2.29525146e+02,  2.39899716e+02,  2.47551516e+02,\n",
       "        1.54008341e+00,  1.99988455e+01, -3.00716584e+00])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(samples_fm, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a3c2545-941b-4a17-a6b4-d01faa7e4cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getdist import MCSamples, plots\n",
    "\n",
    "# param_names = [(\"param1\", r\"\\beta_d\"), (\"param2\", \"T_d\"), (\"param3\", r\"\\beta_s\")]\n",
    "\n",
    "# s1 = MCSamples(samples=samples_fm[:,-3:], names=[p[0] for p in param_names], labels=[p[1] for p in param_names])\n",
    "\n",
    "# g = plots.get_subplot_plotter()\n",
    "# g.triangle_plot([s1], filled=True)\n",
    "\n",
    "# x_vals = [1.54, 20, -3]  # example x positions\n",
    "# y_vals = x_vals  # example y positions\n",
    "\n",
    "# # Access the triangle axes\n",
    "# for ax in g.subplots.flatten():\n",
    "#     if ax is not None:\n",
    "#         for x in x_vals:\n",
    "#             ax.axvline(x, color='k', linestyle='--', linewidth=1)\n",
    "#         for y in y_vals:\n",
    "#             ax.axhline(y, color='k', linestyle='--', linewidth=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df0a518a-fd57-4193-83cd-084a7bf435bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results/samples_bavlv_white.npy', samples_fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5dad4e-432f-4224-bd19-9be1abff44e5",
   "metadata": {},
   "source": [
    "## 5. Estimating r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a3fea77-2970-45d1-bd36-7de2652f6645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weights(A, N):\n",
    "    weights = []\n",
    "    ll, mm = hp.Alm.getlm(nlmax)\n",
    "    \n",
    "    for ell in range(2, nlmax+1):\n",
    "        N_inv_s = np.linalg.inv(N[ell])\n",
    "        ANA = A.T @ N_inv_s @ A  \n",
    "        AN = A.T @ N_inv_s\n",
    "        weights.append((np.linalg.inv(ANA) @ AN))\n",
    "           \n",
    "    return np.array(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b90485d-0f6a-44ea-91f0-b5bef5ec59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_fm = np.load('results/samples_bavlv_white.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33c016af-b676-4ab5-9437-5043eec66b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = np.mean(samples_fm, axis = 0)\n",
    "# params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "643c03d2-4baf-4ce1-acb2-16d6d96e142d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ells = np.arange(2,nlmax+1)\n",
    "coeff = ells*(ells+1)/(2*np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a04663b6-99df-44d6-97dd-7893cec6ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = get_weights(A_evaluator(params[-3:]), Noise_Spectra(noise_rms_pol, alpha_knee = params[:nfreqs], l_knee = params[nfreqs:2*nfreqs], nlmax = nlmax))[:,0]\n",
    "\n",
    "WCW = np.einsum('ij,ijk,ik->i', W, combined_obs_sp[2:], W)\n",
    "WNW = np.einsum('ij,ijk,ik->i', W, noise_sp[2:], W)\n",
    "\n",
    "cmb_rec = np.zeros((nlmax+1))\n",
    "cmb_rec[2:] = WCW/target_beam_p[ells]**2\n",
    "\n",
    "noise_res = np.zeros((nlmax+1))\n",
    "noise_res[2:] = WNW/target_beam_p[ells]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3de83ce-b0cd-42fa-9eb3-4dbedc9fccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results/aps_bavlv_white.npy', np.stack([cmb_rec, noise_res]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f61b5-edbf-49ea-8f1a-703722713fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
